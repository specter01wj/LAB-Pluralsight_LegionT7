import os
import json
import utils
import time

import openai
from openai import OpenAI
# Don't forget to set your OpenAI API key as the environment variable OPENAI_API_KEY
client = OpenAI()

# The model we're going to use, change it if you want
gpt_model = "gpt-3.5-turbo-1106"

def chat_completions_request(messages, model=gpt_model, json_mode=True, tools=None, tool_choice="auto"):
    """
    Send a chat completion request to OpenAI's GPT model.
    
    Parameters
    ----------
    messages : list
        A list of message objects, where each object has a 'role' and 'content'.
    model : str, optional
        The ID of the model to use.
    json_mode : boolean, option
        Determines if JSON mode should be used.
    tools : list, optional
        A list of functions to use in the chat.
    tool_choice : str, optional
        Determines when the model should call a function.

    Returns
    -------
    str
        The message generated by the model in response.

    Raises
    ------
    APIConnectionError, APITimeoutError, InternalServerError
        If the API request fails.
    """
    max_retries = 3  # Number of times to retry the API request in case of failure.
    delay = 5  # Number of seconds to wait between each retry.

    api_params = {
        "model": model,  # Model ID.
        "messages": messages,  # List of message objects.
        "temperature": 0  # This parameter controls the randomness of the model's output.
    }
    
    # To set JSON mode if needed
    if json_mode:
        api_params["response_format"] = { "type": "json_object" } 

    # If functions are passed, we need to add them to the API params
    if tools is not None:
        api_params["tools"] = tools  # List of functions.
        api_params["tool_choice"] = tool_choice  # When the model should call a function.
    
    for attempt in range(max_retries):  # Try to send the request up to max_retries times.
        try:
            # Send the API request and return the model's response.
            response = client.chat.completions.create(**api_params)
            return response.choices[0].message
        except (openai.APIConnectionError, openai.APITimeoutError, openai.InternalServerError) as e:
            # If the request fails and we have retries left, wait for delay seconds and try again.
            if attempt < max_retries - 1:
                print(f"OpenAI API returned an error: {e}")
                print("Retrying...")
                time.sleep(delay)
            else:
                # If we've used all our retries, re-raise the last exception.
                raise e

def process_transcript(transcript):
    """
    Process a conversation transcript, makes requests to a chat completion endpoint,
    and schedules a follow-up call based on the conversation.

    Parameters
    ----------
        transcript (str): The interview transcript to process.
    """

    # Load initial system and user messages
    messages=[
        {"role": "system", "content": utils.open_file("system_prompt.txt")},
        {"role": "user", "content": utils.open_file("user_prompt_01.txt") + transcript}
    ]
    
    # Request chat completion after initial messages
    first_response =  chat_completions_request(messages)

    # Print a message to inform user the information has been extracted
    print("Information extracted...")

    # Append the first response to the messages list
    messages.append(first_response)

    # Convert the first response's content from JSON string to a Python dictionary
    info_object = json.loads(first_response.content.strip())

    # Add another user message to the messages list with the second prompt
    messages.append({"role": "user", "content": utils.open_file("user_prompt_02.txt")})

    # Request another chat completion after adding the user message
    second_response = chat_completions_request(messages)

    # Print a message to inform user the information has been analyzed
    print("Information analyzed...")

    # Append the second response to the messages list
    messages.append(second_response)

    # Convert the second response's content from JSON string to a Python dictionary
    json_to_append = json.loads(second_response.content.strip())

    # Append the second JSON object to the first JSON object
    info_object.update(json_to_append)

    # Save the final JSON object to a file
    utils.save_file(
        json.dumps(info_object, indent=4), 
        f'output/{info_object["candidate"]}-{info_object["datetime"]}.json'
    )
    # Print a message to inform user the information is saved
    print("Information saved...")

    # Add a user message requesting the scheduling of a follow-up call
    messages.append({"role": "user", "content": "Please schedule a follow-up call using the interview date extracted from the transcript."})
    
    # Request a chat completion with the intent of scheduling a follow-up call
    third_response = chat_completions_request(messages, tools=utils.get_follow_up_function_desc())
    
    # Append the third response to the messages list
    messages.append(third_response)
    
    # Extract the field function_call into a variable
    tool_calls = third_response.tool_calls

    # Check if a function was called in the third message
    if tool_calls:
        for tool_call in tool_calls:
            function_message = tool_call.function

            if function_message.name == "schedule_follow_up":
                # Convert the function arguments from JSON string to a Python dictionary
                args = json.loads(function_message.arguments)
        
                # Call the function with the parsed arguments
                function_response = utils.schedule_follow_up(
                    interviewer=args.get("interviewer"),
                    candidate=args.get("candidate"),
                    interview_date=args.get("interview_date"),
                    sentiment=args.get("sentiment")
                )

                # Add the function call and its response to the messages list
                messages.append({
                    "tool_call_id": tool_call.id,
                    "role": "tool",
                    "name": function_message.name,
                    "content": function_response
                })
        
                # Request a final chat completion after scheduling the follow-up call
                fourth_response = chat_completions_request(messages, json_mode=False)
                messages.append(fourth_response)
    else:
        # Print a message if no function was called
        print("No function was called.")
    
    # Print the conversation in a readable format
    utils.pretty_print_conversation(messages)

# Main program 
if __name__ == "__main__":
    # Directory where the transcripts are stored
    directory_path = "transcripts"

    # List all files in directory
    files = os.listdir(directory_path)

    # Loop through each file
    for file in files:
        # Check if the file extension is '.txt'
        if file.endswith('.txt'):
            # Construct the full file path
            file_path = os.path.join(directory_path, file)

            # Reads the file and process the transcript
            process_transcript(utils.open_file(file_path))

